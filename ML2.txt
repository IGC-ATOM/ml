1) Linear regression

import matplotlib.pyplot as plt
from scipy import stats

# Data (Age vs Diabetes cases)
x = [40, 45, 50, 55, 60]
y = [15, 25, 35, 50, 65]

# Linear regression
slope, intercept, r, p, std_err = stats.linregress(x, y)

# Prediction function
def predict(age):
    return slope * age + intercept

# Plot
plt.scatter(x, y, color="blue")
plt.plot(x, [predict(i) for i in x], color="red")
plt.xlabel("Age")
plt.ylabel("Diabetes Occurrence")
plt.title("Diabetes vs Age (40-60)")
plt.show()


___________________________________________________________

import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats

# Dataset
df = pd.DataFrame({
    "Eid": [1, 2, 3, 4, 5],
    "Name": ["Amit", "Neha", "Raj", "Priya", "Karan"],
    "Department": ["IT", "HR", "Finance", "IT", "HR"],
    "Experience": [1, 3, 5, 7, 9],
    "Salary": [25000, 40000, 60000, 80000, 100000]
})
print(df)

# Variables
x, y = df["Experience"], df["Salary"]

# Linear Regression using stats.linregress
slope, intercept, r, p, std_err = stats.linregress(x, y)

def predict(x):
    return slope * x + intercept

# Plot
plt.scatter(x, y, color="blue")
plt.plot(x, list(map(predict, x)), color="red")
plt.show()


_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_

2) Logistic_Regression

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression

# Dataset
df = pd.DataFrame({
    "Age": [22, 25, 28, 35, 40, 45],
    "Salary": [20000, 30000, 35000, 60000, 80000, 100000],
    "Purchased": [0, 0, 0, 1, 1, 1]
})

# Model
X, y = df[["Age", "Salary"]], df["Purchased"]
model = LogisticRegression().fit(X, y)

# Plot
plt.scatter(df["Age"], df["Salary"], c=y, cmap="bwr", edgecolors="k")
plt.xlabel("Age")
plt.ylabel("Salary")
plt.title("Purchase Prediction (Logistic Regression)")
plt.show()

_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_

3) Decision Tree

=> Normal Data
 
import matplotlib.pyplot as plt 
from sklearn.tree import DecisionTreeClassifier,plot_tree
import pandas as pd 

data = {
        "Age" : [34,52,68,22],
        "Income" : [45000, 34000, 23000, 65000],
        "Buy!!" : [1,0,0,1]
        }

df=pd.DataFrame(data)

dt=DecisionTreeClassifier()

x=df[["Age", "Income"]]
y=df["Buy!!"]
dt.fit(x,y)

plot_tree(dt,feature_names=["Age","Income"],class_names=["Buy!!","Not"])

plt.show()

___________________________________________________________


=> Iris Data

import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier, plot_tree

iris = load_iris()
x = iris.data
y = iris.target

clf=DecisionTreeClassifier(random_state=0)
clf.fit(x,y)

plot_tree(clf,feature_names=iris.feature_names, class_names=iris.target_names)
plt.show()

_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_

4) KNN

import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier

# Dataset
X = [[20, 0],[5, 0],[150, 0],
     [0.3, 40],[0.2, 25],[5, 200],
     [190, 0],[220, 0],[80, 0]]
y = [0, 0, 0, 1, 1, 1, 2, 2, 2]  
labels = {0: "Wild Animal", 1: "Bird", 2: "Domestic Animal"}

# KNN Model
knn = KNeighborsClassifier(n_neighbors=3).fit(X, y)

# New creature
new_creature = [[8, 0]]
prediction = knn.predict(new_creature)[0]

print("New creature [8,0] is classified as:", labels[prediction])

# Plot
for cls, color in zip([0,1,2], ["red","green","blue"]):
    points = [X[i] for i in range(len(X)) if y[i]==cls]
    plt.scatter([p[0] for p in points], [p[1] for p in points], 
                c=color, label=labels[cls])

plt.scatter(new_creature[0][0], new_creature[0][1], 
            c="black", marker="o",  label="New Creature")

plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.title("KNN Classification")
plt.legend()
plt.show()


_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_

5) Kmeans & Kmeans Elbow

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Data
X = np.array([[1,2],[1.5,1.8],[5,8],[8,8],[1,0.6],
              [9,11],[8,2],[10,2],[9,3]])

# Elbow method (max clusters = 9)
wcss = [KMeans(n_clusters=i, random_state=42, n_init=10).fit(X).inertia_ for i in range(1, len(X)+1)]
plt.plot(range(1, len(X)+1), wcss, 'o-')
plt.xlabel("Clusters"); plt.ylabel("WCSS"); plt.title("Elbow Method")
plt.show()

# KMeans with 3 clusters
kmeans = KMeans(n_clusters=3, random_state=42, n_init=10).fit(X)
plt.scatter(X[:,0], X[:,1], c=kmeans.labels_, cmap='viridis', s=100)
plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], c='red', marker='s')
plt.title("K-Means Clustering")
plt.show()
